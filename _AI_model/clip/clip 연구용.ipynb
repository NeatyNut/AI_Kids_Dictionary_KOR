{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CLIPProcessor, CLIPModel\n",
    "from PIL import Image\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# 모델버전\n",
    "# 1. python : 3.11.5\n",
    "# 2. pytorch : 2.2.0(cpu)\n",
    "# 3. transformers : 4.32.1\n",
    "# 4. Pillow : 10.0.1\n",
    "\n",
    "# CLIP 모델과 프로세서 로드\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "\n",
    "# 이미지 경로와 텍스트 레이블 목록을 받아서, 이미지에 가장 적합한 텍스트 레이블을 예측합니다.\n",
    "async def predict_text_from_image(path, text_labels):\n",
    "    \n",
    "    # 이미지 로드 및 전처리\n",
    "    image = Image.open(path)\n",
    "\n",
    "    inputs = processor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # 모델을 통해 이미지와 텍스트의 유사도 계산\n",
    "    outputs = clip_model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image # 이미지에 대한 로짓\n",
    "\n",
    "    # 수정 후\n",
    "    probs = logits_per_image.softmax(dim=1).detach().cpu().numpy()\n",
    "\n",
    "    # 가장 높은 확률을 가진 텍스트 레이블을 찾음\n",
    "    max_index = probs.argmax()\n",
    "    predicted_label = text_labels[max_index]\n",
    "\n",
    "    return predicted_label, probs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 : cat\n",
      "확률 : 0.9729471206665039\n"
     ]
    }
   ],
   "source": [
    "## 한국어\n",
    "label, prob = await predict_text_from_image(\"구글_고양이.jpg\", ['고양이', 'cat'])\n",
    "print(f\"라벨 : {label}\")\n",
    "print(f\"확률 : {prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨 : cat\n",
      "확률 : 0.9969338178634644\n"
     ]
    }
   ],
   "source": [
    "## 영어\n",
    "label, prob = await predict_text_from_image(\"google_cat.jpg\", ['고양이', 'cat'])\n",
    "print(f\"라벨 : {label}\")\n",
    "print(f\"확률 : {prob}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_best_englisth = [\n",
    "    \"dog\",\"cat\",\"chicken\",\"pig\",\"horse\",\"fish\",\"snake\",\"magpie\",\"cow\",\"elephant\",\"rabbit\",\"tiger\",\"frog\",\"turtle\",\"whale\",\"bear\",\"lion\",\"sheep\",\"duck\",\"monkey\",\"rat\",\"giraffe\",\"camel\",\"wolf\",\"toad\",\"chick\",\"pigeon\",\"fox\",\"goat\",\"swallow\",\"sparrow\",\"penguin\",\"noodle\",\"candy\",\"tree\",\"flower\",\"soap\",\"gas range\",\"humidifier\",\"scissors\",\"knife\",\"potato\",\"sweat potato\",\"corn\",\"ricecake\",\"cucumber\",\"brook\",\"dry beach\",\"apple\",\"ship\",\"car\",\"plane\",\"computer\",\"notebook computer\",\"television\",\"banana\",\"iron\",\"step\",\"stone\",\"mountain\",\"sea\",\"lunch box\",\"keyboard\",\"mouse\",\"plastic bag\",\"cup\",\"glasses\",\"sprayer\",\"wire\",\"multitap\",\"bottle\",\"handbag\",\"backpack\",\"paper bag\",\"cell phone\",\"bowl\",\"plate\",\"sand\",\"towel\",\"bodywash\",\"cloud\",\"tablet\",\"microwave\",\"city\",\"countryside\",\"needle\",\"box\",\"person\",\"hand\",\"foot\",\"clothing\",\"footwear\",\"hat\",\"makeup\",\"pen\",\"earphone\",\"soup\",\"kimchi\",\"meat\",\"rice\",\"bread\",\"fried food\",\"fan\",\"sausage\",\"air conditioner\",\"dresser\",\"sink\",\"shower head\",\"toilet\",\"washing machine\",\"chair\",\"table\",\"can\",\"clock\",\"watch\",\"refrigerator\",\"egg\",\"remote control\",\"nail clipper\",\"hair drier\",\"razor\",\"doll\",\"book\",\"fork\",\"spoon\",\"chopsticks\",\"cake\",\"shampoo\",\"paper towel\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = [\n",
    "    \"dog\",\"cat\",\"chicken\",\"pig\",\"horse\",\"fish\",\"snake\",\"magpie\",\"cow\",\"elephant\",\"rabbit\",\"tiger\",\"frog\",\"turtle\",\"whale\",\"bear\",\"lion\",\"sheep\",\"duck\",\"monkey\",\"rat\",\"giraffe\",\"camel\",\"wolf\",\"toad\",\"chick\",\"pigeon\",\"fox\",\"goat\",\"swallow\",\"sparrow\",\"penguin\",\"noodle\",\"candy\",\"tree\",\"flower\",\"soap\",\"gas range\",\"humidifier\",\"scissors\",\"knife\",\"potato\",\"sweat potato\",\"corn\",\"ricecake\",\"cucumber\",\"creek\",\"mud flats\",\"apple\",\"ship\",\"car\",\"plane\",\"computer\",\"labtop\",\"tv\",\"banana\",\"steam iron\",\"stair\",\"stone\",\"mountain\",\"sea\",\"lunch box\",\"keyboard\",\"mouse\",\"plastic bag\",\"cup\",\"glasses\",\"sprayer\",\"wire\",\"multitap\",\"bottle\",\"purse\",\"backpack\",\"paper bag\",\"cell phone\",\"bowl\",\"plate\",\"sand\",\"towel\",\"bodywash\",\"cloud\",\"tablet\",\"microwave\",\"city\",\"countryside\",\"needle\",\"box\",\"person\",\"hand\",\"foot\",\"clothing\",\"shoes\",\"hat\",\"cosmetics\",\"pen\",\"earphone\",\"soup\",\"kimchi\",\"meat\",\"rice\",\"bread\",\"fried food\",\"fan\",\"sausage\",\"air conditioner\",\"drawer\",\"sink\",\"shower head\",\"toilet\",\"washing machine\",\"chair\",\"table\",\"can\",\"clock\",\"watch\",\"refrigerator\",\"egg\",\"remote control\",\"nail clipper\",\"hair drier\",\"razor\",\"doll\",\"book\",\"fork\",\"spoon\",\"chopsticks\",\"cake\",\"shampoo\",\"paper towel\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "korean = [\n",
    "    \"개\",\"고양이\",\"닭\",\"돼지\",\"말\",\"물고기\",\"뱀\",\"까치\",\"소\",\"코끼리\",\"토끼\",\"호랑이\",\"개구리\",\"거북이\",\"고래\",\"곰\",\"사자\",\"양\",\"오리\",\"원숭이\",\"쥐\",\"기린\",\"낙타\",\"늑대\",\"두꺼비\",\"병아리\",\"비둘기\",\"여우\",\"염소\",\"제비\",\"참새\",\"펭귄\",\"국수\",\"사탕\",\"나무\",\"꽃\",\"비누\",\"가스레인지\",\"가습기\",\"가위\",\"칼\",\"감자\",\"고구마\",\"옥수수\",\"떡\",\"오이\",\"개천\",\"갯벌\",\"사과\",\"배\",\"차\",\"비행기\",\"컴퓨터\",\"노트북\",\"텔레비전\",\"바나나\",\"다리미\",\"계단\",\"돌\",\"산\",\"바다\",\"도시락\",\"키보드\",\"마우스\",\"비닐봉투\",\"컵\",\"안경\",\"분무기\",\"전선\",\"멀티탭\",\"병\",\"손가방\",\"가방\",\"종이가방\",\"핸드폰\",\"그릇\",\"접시\",\"모래\",\"수건\",\"바디워시\",\"구름\",\"태블릿\",\"전자레인지\",\"도시\",\"시골\",\"바늘\",\"박스\",\"사람\",\"손\",\"발\",\"옷\",\"신발\",\"모자\",\"화장품\",\"필기구\",\"이어폰\",\"국\",\"김치\",\"고기\",\"밥\",\"빵\",\"튀김\",\"선풍기\",\"소시지\",\"에어컨\",\"서랍장\",\"싱크대\",\"샤워기\",\"변기\",\"세탁기\",\"의자\",\"탁자\",\"캔\",\"시계\",\"손목시계\",\"냉장고\",\"달걀\",\"리모컨\",\"손톱깎이\",\"헤어드라이어\",\"면도기\",\"인형\",\"책\",\"포크\",\"숟가락\",\"젓가락\",\"케잌\",\"샴푸\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "photoofenglish = [\n",
    "    \"a photo of dog\",\"a photo of cat\",\"a photo of chicken\",\"a photo of pig\",\"a photo of horse\",\"a photo of fish\",\"a photo of snake\",\"a photo of magpie\",\"a photo of cow\",\"a photo of elephant\",\"a photo of rabbit\",\"a photo of tiger\",\"a photo of frog\",\"a photo of turtle\",\"a photo of whale\",\"a photo of bear\",\"a photo of lion\",\"a photo of sheep\",\"a photo of duck\",\"a photo of monkey\",\"a photo of rat\",\"a photo of giraffe\",\"a photo of camel\",\"a photo of wolf\",\"a photo of toad\",\"a photo of chick\",\"a photo of pigeon\",\"a photo of fox\",\"a photo of goat\",\"a photo of swallow\",\"a photo of sparrow\",\"a photo of penguin\",\"a photo of noodle\",\"a photo of candy\",\"a photo of tree\",\"a photo of flower\",\"a photo of soap\",\"a photo of gas range\",\"a photo of humidifier\",\"a photo of scissors\",\"a photo of knife\",\"a photo of potato\",\"a photo of sweat potato\",\"a photo of corn\",\"a photo of ricecake\",\"a photo of cucumber\",\"a photo of creek\",\"a photo of mud flats\",\"a photo of apple\",\"a photo of ship\",\"a photo of car\",\"a photo of plane\",\"a photo of computer\",\"a photo of labtop\",\"a photo of tv\",\"a photo of banana\",\"a photo of steam iron\",\"a photo of stair\",\"a photo of stone\",\"a photo of mountain\",\"a photo of sea\",\"a photo of lunch box\",\"a photo of keyboard\",\"a photo of mouse\",\"a photo of plastic bag\",\"a photo of cup\",\"a photo of glasses\",\"a photo of sprayer\",\"a photo of wire\",\"a photo of multitap\",\"a photo of bottle\",\"a photo of purse\",\"a photo of backpack\",\"a photo of paper bag\",\"a photo of cell phone\",\"a photo of bowl\",\"a photo of plate\",\"a photo of sand\",\"a photo of towel\",\"a photo of bodywash\",\"a photo of cloud\",\"a photo of tablet\",\"a photo of microwave\",\"a photo of city\",\"a photo of countryside\",\"a photo of needle\",\"a photo of box\",\"a photo of person\",\"a photo of hand\",\"a photo of foot\",\"a photo of clothing\",\"a photo of shoes\",\"a photo of hat\",\"a photo of cosmetics\",\"a photo of pen\",\"a photo of earphone\",\"a photo of soup\",\"a photo of kimchi\",\"a photo of meat\",\"a photo of rice\",\"a photo of bread\",\"a photo of fried food\",\"a photo of fan\",\"a photo of sausage\",\"a photo of air conditioner\",\"a photo of drawer\",\"a photo of sink\",\"a photo of shower head\",\"a photo of toilet\",\"a photo of washing machine\",\"a photo of chair\",\"a photo of table\",\"a photo of can\",\"a photo of clock\",\"a photo of watch\",\"a photo of refrigerator\",\"a photo of egg\",\"a photo of remote control\",\"a photo of nail clipper\",\"a photo of hair drier\",\"a photo of razor\",\"a photo of doll\",\"a photo of book\",\"a photo of fork\",\"a photo of spoon\",\"a photo of chopsticks\",\"a photo of cake\",\"a photo of shampoo\",\"a photo of paper towel\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008\n",
      "0.016\n",
      "0.023\n",
      "0.031\n",
      "0.039\n",
      "0.047\n",
      "0.054\n",
      "0.062\n",
      "0.07\n",
      "0.078\n",
      "0.085\n",
      "0.093\n",
      "0.101\n",
      "0.109\n",
      "0.116\n",
      "0.124\n",
      "0.132\n",
      "0.14\n",
      "0.147\n",
      "0.155\n",
      "0.163\n",
      "0.171\n",
      "0.178\n",
      "0.186\n",
      "0.194\n",
      "0.202\n",
      "0.209\n",
      "0.217\n",
      "0.225\n",
      "0.233\n",
      "0.24\n",
      "0.248\n",
      "0.256\n",
      "0.264\n",
      "0.271\n",
      "0.279\n",
      "0.287\n",
      "0.295\n",
      "0.302\n",
      "0.31\n",
      "0.318\n",
      "0.326\n",
      "0.333\n",
      "0.341\n",
      "0.349\n",
      "0.357\n",
      "0.364\n",
      "0.372\n",
      "0.38\n",
      "0.388\n",
      "0.395\n",
      "0.403\n",
      "0.411\n",
      "0.419\n",
      "0.426\n",
      "0.434\n",
      "0.442\n",
      "0.45\n",
      "0.457\n",
      "0.465\n",
      "0.473\n",
      "0.481\n",
      "0.488\n",
      "0.496\n",
      "0.504\n",
      "0.512\n",
      "0.519\n",
      "0.527\n",
      "0.535\n",
      "0.543\n",
      "0.55\n",
      "0.558\n",
      "0.566\n",
      "0.574\n",
      "0.581\n",
      "0.589\n",
      "0.597\n",
      "0.605\n",
      "0.612\n",
      "0.62\n",
      "0.628\n",
      "0.636\n",
      "0.643\n",
      "0.651\n",
      "0.659\n",
      "0.667\n",
      "0.674\n",
      "0.682\n",
      "0.69\n",
      "0.698\n",
      "0.705\n",
      "0.713\n",
      "0.721\n",
      "0.729\n",
      "0.736\n",
      "0.744\n",
      "0.752\n",
      "0.76\n",
      "0.767\n",
      "0.775\n",
      "0.783\n",
      "0.791\n",
      "0.798\n",
      "0.806\n",
      "0.814\n",
      "0.822\n",
      "0.829\n",
      "0.837\n",
      "0.845\n",
      "0.853\n",
      "0.86\n",
      "0.868\n",
      "0.876\n",
      "0.884\n",
      "0.891\n",
      "0.899\n",
      "0.907\n",
      "0.915\n",
      "0.922\n",
      "0.93\n",
      "0.938\n",
      "0.946\n",
      "0.953\n",
      "0.961\n",
      "0.969\n",
      "0.977\n",
      "0.984\n",
      "0.992\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), '데이터')\n",
    "eng_result = pd.DataFrame(columns=['jpg','label', 'prob'])\n",
    "file_list = os.listdir(path)\n",
    "file_number = len(file_list)\n",
    "\n",
    "for idx, i in enumerate(file_list):\n",
    "    label, prob = await predict_text_from_image(os.path.join(path, i), english)\n",
    "    eng_result.loc[idx] = [i, label, prob]\n",
    "    eng_result.to_csv('eng_result.csv', encoding='cp949')\n",
    "    print(round((idx+1) / file_number,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008\n",
      "0.016\n",
      "0.023\n",
      "0.031\n",
      "0.039\n",
      "0.047\n",
      "0.054\n",
      "0.062\n",
      "0.07\n",
      "0.078\n",
      "0.085\n",
      "0.093\n",
      "0.101\n",
      "0.109\n",
      "0.116\n",
      "0.124\n",
      "0.132\n",
      "0.14\n",
      "0.147\n",
      "0.155\n",
      "0.163\n",
      "0.171\n",
      "0.178\n",
      "0.186\n",
      "0.194\n",
      "0.202\n",
      "0.209\n",
      "0.217\n",
      "0.225\n",
      "0.233\n",
      "0.24\n",
      "0.248\n",
      "0.256\n",
      "0.264\n",
      "0.271\n",
      "0.279\n",
      "0.287\n",
      "0.295\n",
      "0.302\n",
      "0.31\n",
      "0.318\n",
      "0.326\n",
      "0.333\n",
      "0.341\n",
      "0.349\n",
      "0.357\n",
      "0.364\n",
      "0.372\n",
      "0.38\n",
      "0.388\n",
      "0.395\n",
      "0.403\n",
      "0.411\n",
      "0.419\n",
      "0.426\n",
      "0.434\n",
      "0.442\n",
      "0.45\n",
      "0.457\n",
      "0.465\n",
      "0.473\n",
      "0.481\n",
      "0.488\n",
      "0.496\n",
      "0.504\n",
      "0.512\n",
      "0.519\n",
      "0.527\n",
      "0.535\n",
      "0.543\n",
      "0.55\n",
      "0.558\n",
      "0.566\n",
      "0.574\n",
      "0.581\n",
      "0.589\n",
      "0.597\n",
      "0.605\n",
      "0.612\n",
      "0.62\n",
      "0.628\n",
      "0.636\n",
      "0.643\n",
      "0.651\n",
      "0.659\n",
      "0.667\n",
      "0.674\n",
      "0.682\n",
      "0.69\n",
      "0.698\n",
      "0.705\n",
      "0.713\n",
      "0.721\n",
      "0.729\n",
      "0.736\n",
      "0.744\n",
      "0.752\n",
      "0.76\n",
      "0.767\n",
      "0.775\n",
      "0.783\n",
      "0.791\n",
      "0.798\n",
      "0.806\n",
      "0.814\n",
      "0.822\n",
      "0.829\n",
      "0.837\n",
      "0.845\n",
      "0.853\n",
      "0.86\n",
      "0.868\n",
      "0.876\n",
      "0.884\n",
      "0.891\n",
      "0.899\n",
      "0.907\n",
      "0.915\n",
      "0.922\n",
      "0.93\n",
      "0.938\n",
      "0.946\n",
      "0.953\n",
      "0.961\n",
      "0.969\n",
      "0.977\n",
      "0.984\n",
      "0.992\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), '데이터')\n",
    "kor_result = pd.DataFrame(columns=['jpg','label', 'prob'])\n",
    "file_list = os.listdir(path)\n",
    "file_number = len(file_list)\n",
    "\n",
    "for idx, i in enumerate(file_list):\n",
    "    label, prob = await predict_text_from_image(os.path.join(path, i), korean)\n",
    "    eng_result.loc[idx] = [i, label, prob]\n",
    "    eng_result.to_csv('kor_result.csv', encoding='cp949')\n",
    "    print(round((idx+1) / file_number,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008\n",
      "0.016\n",
      "0.023\n",
      "0.031\n",
      "0.039\n",
      "0.047\n",
      "0.054\n",
      "0.062\n",
      "0.07\n",
      "0.078\n",
      "0.085\n",
      "0.093\n",
      "0.101\n",
      "0.109\n",
      "0.116\n",
      "0.124\n",
      "0.132\n",
      "0.14\n",
      "0.147\n",
      "0.155\n",
      "0.163\n",
      "0.171\n",
      "0.178\n",
      "0.186\n",
      "0.194\n",
      "0.202\n",
      "0.209\n",
      "0.217\n",
      "0.225\n",
      "0.233\n",
      "0.24\n",
      "0.248\n",
      "0.256\n",
      "0.264\n",
      "0.271\n",
      "0.279\n",
      "0.287\n",
      "0.295\n",
      "0.302\n",
      "0.31\n",
      "0.318\n",
      "0.326\n",
      "0.333\n",
      "0.341\n",
      "0.349\n",
      "0.357\n",
      "0.364\n",
      "0.372\n",
      "0.38\n",
      "0.388\n",
      "0.395\n",
      "0.403\n",
      "0.411\n",
      "0.419\n",
      "0.426\n",
      "0.434\n",
      "0.442\n",
      "0.45\n",
      "0.457\n",
      "0.465\n",
      "0.473\n",
      "0.481\n",
      "0.488\n",
      "0.496\n",
      "0.504\n",
      "0.512\n",
      "0.519\n",
      "0.527\n",
      "0.535\n",
      "0.543\n",
      "0.55\n",
      "0.558\n",
      "0.566\n",
      "0.574\n",
      "0.581\n",
      "0.589\n",
      "0.597\n",
      "0.605\n",
      "0.612\n",
      "0.62\n",
      "0.628\n",
      "0.636\n",
      "0.643\n",
      "0.651\n",
      "0.659\n",
      "0.667\n",
      "0.674\n",
      "0.682\n",
      "0.69\n",
      "0.698\n",
      "0.705\n",
      "0.713\n",
      "0.721\n",
      "0.729\n",
      "0.736\n",
      "0.744\n",
      "0.752\n",
      "0.76\n",
      "0.767\n",
      "0.775\n",
      "0.783\n",
      "0.791\n",
      "0.798\n",
      "0.806\n",
      "0.814\n",
      "0.822\n",
      "0.829\n",
      "0.837\n",
      "0.845\n",
      "0.853\n",
      "0.86\n",
      "0.868\n",
      "0.876\n",
      "0.884\n",
      "0.891\n",
      "0.899\n",
      "0.907\n",
      "0.915\n",
      "0.922\n",
      "0.93\n",
      "0.938\n",
      "0.946\n",
      "0.953\n",
      "0.961\n",
      "0.969\n",
      "0.977\n",
      "0.984\n",
      "0.992\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), '데이터')\n",
    "eng_result = pd.DataFrame(columns=['jpg','label', 'prob'])\n",
    "file_list = os.listdir(path)\n",
    "file_number = len(file_list)\n",
    "\n",
    "for idx, i in enumerate(file_list):\n",
    "    label, prob = await predict_text_from_image(os.path.join(path, i), not_best_englisth)\n",
    "    eng_result.loc[idx] = [i, label, prob]\n",
    "    eng_result.to_csv('not_best_eng_result.csv', encoding='cp949')\n",
    "    print(round((idx+1) / file_number,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008\n",
      "0.016\n",
      "0.023\n",
      "0.031\n",
      "0.039\n",
      "0.047\n",
      "0.054\n",
      "0.062\n",
      "0.07\n",
      "0.078\n",
      "0.085\n",
      "0.093\n",
      "0.101\n",
      "0.109\n",
      "0.116\n",
      "0.124\n",
      "0.132\n",
      "0.14\n",
      "0.147\n",
      "0.155\n",
      "0.163\n",
      "0.171\n",
      "0.178\n",
      "0.186\n",
      "0.194\n",
      "0.202\n",
      "0.209\n",
      "0.217\n",
      "0.225\n",
      "0.233\n",
      "0.24\n",
      "0.248\n",
      "0.256\n",
      "0.264\n",
      "0.271\n",
      "0.279\n",
      "0.287\n",
      "0.295\n",
      "0.302\n",
      "0.31\n",
      "0.318\n",
      "0.326\n",
      "0.333\n",
      "0.341\n",
      "0.349\n",
      "0.357\n",
      "0.364\n",
      "0.372\n",
      "0.38\n",
      "0.388\n",
      "0.395\n",
      "0.403\n",
      "0.411\n",
      "0.419\n",
      "0.426\n",
      "0.434\n",
      "0.442\n",
      "0.45\n",
      "0.457\n",
      "0.465\n",
      "0.473\n",
      "0.481\n",
      "0.488\n",
      "0.496\n",
      "0.504\n",
      "0.512\n",
      "0.519\n",
      "0.527\n",
      "0.535\n",
      "0.543\n",
      "0.55\n",
      "0.558\n",
      "0.566\n",
      "0.574\n",
      "0.581\n",
      "0.589\n",
      "0.597\n",
      "0.605\n",
      "0.612\n",
      "0.62\n",
      "0.628\n",
      "0.636\n",
      "0.643\n",
      "0.651\n",
      "0.659\n",
      "0.667\n",
      "0.674\n",
      "0.682\n",
      "0.69\n",
      "0.698\n",
      "0.705\n",
      "0.713\n",
      "0.721\n",
      "0.729\n",
      "0.736\n",
      "0.744\n",
      "0.752\n",
      "0.76\n",
      "0.767\n",
      "0.775\n",
      "0.783\n",
      "0.791\n",
      "0.798\n",
      "0.806\n",
      "0.814\n",
      "0.822\n",
      "0.829\n",
      "0.837\n",
      "0.845\n",
      "0.853\n",
      "0.86\n",
      "0.868\n",
      "0.876\n",
      "0.884\n",
      "0.891\n",
      "0.899\n",
      "0.907\n",
      "0.915\n",
      "0.922\n",
      "0.93\n",
      "0.938\n",
      "0.946\n",
      "0.953\n",
      "0.961\n",
      "0.969\n",
      "0.977\n",
      "0.984\n",
      "0.992\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), '데이터')\n",
    "eng_result = pd.DataFrame(columns=['jpg','label', 'prob'])\n",
    "file_list = os.listdir(path)\n",
    "file_number = len(file_list)\n",
    "\n",
    "for idx, i in enumerate(file_list):\n",
    "    label, prob = await predict_text_from_image(os.path.join(path, i), photoofenglish)\n",
    "    eng_result.loc[idx] = [i, label, prob]\n",
    "    eng_result.to_csv('photoofenglish_eng_result.csv', encoding='cp949')\n",
    "    print(round((idx+1) / file_number,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6e5e9283e604a50a085ef6b4c905c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/380 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\uilov\\anaconda3\\Lib\\site-packages\\huggingface_hub\\file_download.py:133: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\uilov\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bb86ee19c4450c9c2ebe71d758344a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer_config.json:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7597f960a7404cd691456a7c3f377e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading vocab.json:   0%|          | 0.00/1.21M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd30358eeb6147ae95d984afe84838de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading merges.txt:   0%|          | 0.00/870k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34f207926e4450a9f6bc4215373b587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading tokenizer.json:   0%|          | 0.00/2.91M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b30342e0d34670afad730e4d566d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/472 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b544ac4b41e428e8caf7ce6ae2e7302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading config.json:   0%|          | 0.00/4.88k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"id2label\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"bos_token_id\"]` will be overriden.\n",
      "`text_config_dict` is provided which will be used to initialize `CLIPTextConfig`. The value `text_config[\"eos_token_id\"]` will be overriden.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1994643ed596401a8044948875a1f6c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading model.safetensors:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "\n",
    "# 모델버전\n",
    "# 1. python : 3.11.5\n",
    "# 2. pytorch : 2.2.0(cpu)\n",
    "# 3. transformers : 4.32.1\n",
    "# 4. Pillow : 10.0.1\n",
    "\n",
    "# CLIP 모델과 프로세서 로드\n",
    "koprocessor = AutoProcessor.from_pretrained(\"Bingsu/clip-vit-large-patch14-ko\")\n",
    "koclip_model = AutoModel.from_pretrained(\"Bingsu/clip-vit-large-patch14-ko\")\n",
    "\n",
    "# 이미지 경로와 텍스트 레이블 목록을 받아서, 이미지에 가장 적합한 텍스트 레이블을 예측합니다.\n",
    "async def ko_predict_text_from_image(path, text_labels):\n",
    "    \n",
    "    # 이미지 로드 및 전처리\n",
    "    image = Image.open(path)\n",
    "\n",
    "    inputs = koprocessor(text=text_labels, images=image, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "    # 모델을 통해 이미지와 텍스트의 유사도 계산\n",
    "    with torch.inference_mode():\n",
    "        outputs = koclip_model(**inputs)\n",
    "    logits_per_image = outputs.logits_per_image # 이미지에 대한 로짓\n",
    "\n",
    "    # 수정 후\n",
    "    probs = logits_per_image.softmax(dim=1).detach().cpu().numpy()\n",
    "\n",
    "    # 가장 높은 확률을 가진 텍스트 레이블을 찾음\n",
    "    max_index = probs.argmax()\n",
    "    predicted_label = text_labels[max_index]\n",
    "\n",
    "    return predicted_label, probs.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.008\n",
      "0.016\n",
      "0.023\n",
      "0.031\n",
      "0.039\n",
      "0.047\n",
      "0.054\n",
      "0.062\n",
      "0.07\n",
      "0.078\n",
      "0.085\n",
      "0.093\n",
      "0.101\n",
      "0.109\n",
      "0.116\n",
      "0.124\n",
      "0.132\n",
      "0.14\n",
      "0.147\n",
      "0.155\n",
      "0.163\n",
      "0.171\n",
      "0.178\n",
      "0.186\n",
      "0.194\n",
      "0.202\n",
      "0.209\n",
      "0.217\n",
      "0.225\n",
      "0.233\n",
      "0.24\n",
      "0.248\n",
      "0.256\n",
      "0.264\n",
      "0.271\n",
      "0.279\n",
      "0.287\n",
      "0.295\n",
      "0.302\n",
      "0.31\n",
      "0.318\n",
      "0.326\n",
      "0.333\n",
      "0.341\n",
      "0.349\n",
      "0.357\n",
      "0.364\n",
      "0.372\n",
      "0.38\n",
      "0.388\n",
      "0.395\n",
      "0.403\n",
      "0.411\n",
      "0.419\n",
      "0.426\n",
      "0.434\n",
      "0.442\n",
      "0.45\n",
      "0.457\n",
      "0.465\n",
      "0.473\n",
      "0.481\n",
      "0.488\n",
      "0.496\n",
      "0.504\n",
      "0.512\n",
      "0.519\n",
      "0.527\n",
      "0.535\n",
      "0.543\n",
      "0.55\n",
      "0.558\n",
      "0.566\n",
      "0.574\n",
      "0.581\n",
      "0.589\n",
      "0.597\n",
      "0.605\n",
      "0.612\n",
      "0.62\n",
      "0.628\n",
      "0.636\n",
      "0.643\n",
      "0.651\n",
      "0.659\n",
      "0.667\n",
      "0.674\n",
      "0.682\n",
      "0.69\n",
      "0.698\n",
      "0.705\n",
      "0.713\n",
      "0.721\n",
      "0.729\n",
      "0.736\n",
      "0.744\n",
      "0.752\n",
      "0.76\n",
      "0.767\n",
      "0.775\n",
      "0.783\n",
      "0.791\n",
      "0.798\n",
      "0.806\n",
      "0.814\n",
      "0.822\n",
      "0.829\n",
      "0.837\n",
      "0.845\n",
      "0.853\n",
      "0.86\n",
      "0.868\n",
      "0.876\n",
      "0.884\n",
      "0.891\n",
      "0.899\n",
      "0.907\n",
      "0.915\n",
      "0.922\n",
      "0.93\n",
      "0.938\n",
      "0.946\n",
      "0.953\n",
      "0.961\n",
      "0.969\n",
      "0.977\n",
      "0.984\n",
      "0.992\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "path = os.path.join(os.getcwd(), '데이터')\n",
    "kor_result = pd.DataFrame(columns=['jpg','label', 'prob'])\n",
    "file_list = os.listdir(path)\n",
    "file_number = len(file_list)\n",
    "\n",
    "for idx, i in enumerate(file_list):\n",
    "    label, prob = await ko_predict_text_from_image(os.path.join(path, i), korean)\n",
    "    eng_result.loc[idx] = [i, label, prob]\n",
    "    eng_result.to_csv('koclip_result.csv', encoding='cp949')\n",
    "    print(round((idx+1) / file_number,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'razor'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label, prob = await predict_text_from_image('데이터/razor.jpg', ['shaver', 'razor'])\n",
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8695202"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
